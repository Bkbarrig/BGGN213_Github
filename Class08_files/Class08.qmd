---
title: "Class 08: Machine Learning Mini Project"
author: "Bianca Barriga"
format: pdf
---

Function focus for today: grep(), kmeans(), hclust(), prcomp()

#Import the dataset

Before we can begin our analysis we first have to download and import our data correctly into our R ression. 

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names=1)
head(wisc.df)
```
>Q1. How many samples are in this dataset?

```{r}
nrow(wisc.df)
ncol(wisc.df)
```
>Q. How many variables (columns)?


```{r}
ncol(wisc.df)
```


>Q2. How many M and B samples are there? 

```{r}
table(wisc.df$diagnosis)
```

>Q3. How many variables/features in the data are suffixed with _mean?

```{r}

txt <- c("_mean")
length(grep(txt, colnames(wisc.df), value =TRUE))



```
Q. what feathers are "mean" values?
```{r}
txt <- c("_mean")
grep(txt, colnames(wisc.df), value =TRUE)
```

I need to remove the first diagnosis column from my data before doing any analysis. I will store it for later. 

```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]

```


```{r}
# Create diagnosis vector for later 
diagnosis <- as.factor(wisc.df$diagnosis)
```

#2. Principal Component Analysis 

The main PCA function in base R is called `prcom()`. 

Before doing anything like PCA, it is important to check if the data need to be scaled before performing PCA. Recall two common reasons for scaling data include:

-The input variables use different units of measurement.
-The input variables have significantly different variances.


```{r}
#checking sd of data
round(apply(wisc.data, 2, sd), 2)
```
Looks like we need to scare by setting `scale = TRUE` in our `prcomp()` function call. 

#Time for PCA

```{r}

wisc.pr <- prcomp(wisc.data, scale = TRUE)
summary(wisc.pr)

```

It's good practice to make a SCREE plot and look for inflection point.

```{r}
attributes(wisc.pr)
```
```{r}
pr.var <- wisc.pr$sdev^2
#proportion of variance
pve <- pr.var/sum(pr.var)
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

```

Let's make our main results figure from our PCA - our score plot (a.k.a "PC plot","PC1vsPC2 plot", etc)



```{r}

library(ggplot2)
pc <- as.data.frame(wisc.pr$x)
  
  ggplot(pc) +
  aes(PC1, PC2, col = diagnosis) +
  geom_point()
  
```



#Hierachical clustering 

Preparation for hierachical clustering, the distance between all pairs of observations are computed. Futhhermore, there are different ways to link clusters together, with single, complete, and average being teh most common "linkage methods. 

We can try clustering the original data with `hclut()` or `kmeans()`

First scale wisc.data and and assign the result to data.scaled. 
```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)

```

```{r}
head(apply(data.scaled,2, sd))

```

Calculate the (Euclidean) distance between all pairs of observations in teh new scaled dataset and assign the result to data.dist. 

Create a hierarchical clustering model using complete linkage. Manually specify the method argument to hclust() and assign the results to wisc.hclust.

```{r}
wisc.hclust <- hclust(dist(data.scaled))
wisc.hclust
```
Let’s use the hierarchical clustering model you just created to determine a height (or distance between clusters) where a certain number of clusters exists.
 

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```
To get a cluster membership vector I will use the `cutree()` function and "cut" into 4 or so grps or clusters. 

```{r}
grps <- cutree(wisc.hclust, h=19)
table(grps)
```

I can also use the `table()` to cross tabulate...

```{r}
table(diagnosis)
```
We can use the table() function to compare the cluster membership to the actual diagnoses.

```{r}
table(grps, diagnosis)
```

#Clustering on PCA results 

I can cluster in PC-space and use as many or as few PCs as I want. 

To start with I will use 3 PCs, that is I will cluster along PC1, PC2, and PC3. Those 3 PCs capture about 70% of variance. 

```{r}
#calculate distance and select columns 1:3 for PC1-3. 
pc.dist <- dist(wisc.pr$x[,1:3])
#use hclust
wisc.pr.hclust <- hclust(pc.dist, method = "ward.D2")
#plot
plot(wisc.pr.hclust)
```

This looks much nicer than our previous clustering result. Let's find the two major clusters wiht `cutree` function. 

This looks much more promising than our previous clustering results on the original scaled data. Note the two main branches of or dendrogram indicating two main clusters - maybe these are malignant and benign. Let’s find out!
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps, diagnosis)

#According to our clustering. Cluster 1 groups is associated with malignancy and Cluster 2 groups is associated with benign. 
```

We could calculate accuracy - the proportion of samples we got correct if we take cluster 1 to represent all M and cluster 2 to represent all B. 

```{r}
(179+333)/nrow(wisc.data)
```

```{r}

    
plot(wisc.pr$x[,1:2], col=grps)

```
```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)

```
>Q.14 How well do the hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses

We could calculate accuracy - the proportion of samples we got correct if we take cluster 1 to represent all M and cluster 2 to represent all B. 

```{r}
(179+333)/nrow(wisc.data)
```

#Sensitivity/Specificity

Sensitivity refers to a test’s ability to correctly detect ill patients who do have the condition. In our example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

#According to our clustering. Cluster 1 groups is associated with malignancy and Cluster 2 groups is associated with benign. When we table our clusters and sort by diagnosis, we notice that in Cluster 1 and Cluster 2 we have patients that are B/M, so false positives or flase negatives and this can be used to calculate sensitivity/specificity

```{r}
TP = 179
FN = 24

table(grps, diagnosis)
sensitivity <- TP/(TP+FN)
sensitivity

```
Specificity relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN)

```{r}
TN = 333
FN = 33
specificity <- TN/(TN+FN)
specificity 
```



Specificity relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).

>Q15. OPTIONAL: Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

#Prediction
We will use the predict() function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```


```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```
 
 >Q16. Which of these new patients should we prioritize for follow up based on your results? 
 patient 2

